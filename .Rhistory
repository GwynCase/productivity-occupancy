pfa.predicted <- bind_cols(pfa.predicted, setNames(as_tibble(predict(pfa.top.model, pfa.predicted,
se.fit = TRUE)[1:2]),
c('fit.link','se.link')))
# Create confidence interval.
pfa.predicted <- pfa.predicted %>% mutate(fit.resp  = inv(fit.link),
right.upr = inv(fit.link + (2 * se.link)),
right.lwr = inv(fit.link - (2 * se.link)))
# Plot them?
ggplot(pfa.predicted, aes(x=gap.edge.density, y=pred)) +
geom_line() +
geom_ribbon(aes(ymin=right.lwr, ymax=right.upr), alpha=0.1) +
geom_point(data=pfa.data, aes(x=gap.edge.density, y=quality.index)) +
theme_classic()
summary(pfa.top.model)
# Look at some diagnostics.
data.frame(predicted=predict(pfa.top.model, type='response'),
residuals=residuals(pfa.top.model, type='response')) %>%
ggplot(aes(x=predicted, y=residuals)) +
geom_point() +
geom_hline(yintercept=0, linetype='dashed') +
geom_smooth(method='lm', se=FALSE, color='black') +
theme_classic()
pfa.models %>% mutate(glance=map(model, glance)) %>%
unnest(glance) %>% ungroup() %>%
select(!c(size, data, model))
pfa.models %>% mutate(tidy=map(model, tidy)) %>%
unnest(tidy) %>% ungroup() %>%
select(!c(size, data, model)) %>%
filter(term != '(Intercept)')
aictab(ba.models$model, modnames=pfa.models$modname) %>%
kable() %>% kable_styling(bootstrap_options=c('striped'))
# Separate out the data.
ba.data <- df %>% filter(size == 'breeding area')
# Re-write the top model on its own.
ba.top.model <- glm(cbind(years.detect, years.no.detect) ~ proportion.cover.mature +
gap.edge.density, data=ba.data, family=binomial(logit))
# Create a grid and add predictions.
ba.predicted <- data_grid(ba.data, gap.edge.density, .model=ba.top.model) %>%
mutate(pred=predict(ba.top.model, newdata=., type='response'))
# Grab the inverse link function from the model.
ba.inv <- family(ba.top.model)$linkinv
# Add fit and SE data.
ba.predicted <- bind_cols(ba.predicted, setNames(as_tibble(predict(ba.top.model, ba.predicted,
se.fit = TRUE)[1:2]),
c('fit.link','se.link')))
# Create confidence interval.
ba.predicted <- ba.predicted %>% mutate(fit.resp  = ba.inv(fit.link),
right.upr = ba.inv(fit.link + (2 * se.link)),
right.lwr = ba.inv(fit.link - (2 * se.link)))
# Plot them?
ggplot(ba.predicted, aes(x=gap.edge.density, y=pred)) +
geom_line() +
geom_ribbon(aes(ymin=right.lwr, ymax=right.upr), alpha=0.1) +
geom_point(data=ba.data, aes(x=gap.edge.density, y=quality.index)) +
theme_classic()
summary(ba.top.model)
# Look at some diagnostics.
data.frame(predicted=predict(ba.top.model, type='response'),
residuals=residuals(ba.top.model, type='response')) %>%
ggplot(aes(x=predicted, y=residuals)) +
geom_point() +
geom_hline(yintercept=0, linetype='dashed') +
geom_smooth(method='lm', se=FALSE, color='black') +
theme_classic()
ba.models %>% mutate(glance=map(model, glance)) %>%
unnest(glance) %>% ungroup() %>%
select(!c(size, data, model))
ba.models %>% mutate(tidy=map(model, tidy)) %>%
unnest(tidy) %>% ungroup() %>%
select(!c(size, data, model)) %>%
filter(term != '(Intercept)')
aictab(hr.models$model, modnames=pfa.models$modname) %>%
kable() %>% kable_styling(bootstrap_options=c('striped'))
hr.models %>% mutate(glance=map(model, glance)) %>%
unnest(glance) %>% ungroup() %>%
select(!c(size, data, model))
hr.models %>% mutate(tidy=map(model, tidy)) %>%
unnest(tidy) %>% ungroup() %>%
select(!c(size, data, model)) %>%
filter(term != '(Intercept)')
aictab(mr.models$model, modnames=pfa.models$modname) %>%
kable() %>% kable_styling(bootstrap_options=c('striped'))
mr.models %>% mutate(glance=map(model, glance)) %>%
unnest(glance) %>% ungroup() %>%
select(!c(size, data, model))
mr.models %>% mutate(tidy=map(model, tidy)) %>%
unnest(tidy) %>% ungroup() %>%
select(!c(size, data, model)) %>%
filter(term != '(Intercept)')
aictab(hr.models$model, modnames=ht.models$modname) %>%
kable() %>% kable_styling(bootstrap_options=c('striped'))
aictab(hr.models$model, modnames=hr.models$modname) %>%
kable() %>% kable_styling(bootstrap_options=c('striped'))
aictab(mr.models$model, modnames=mr.models$modname) %>%
kable() %>% kable_styling(bootstrap_options=c('striped'))
aictab(ba.models$model, modnames=ba.models$modname) %>%
kable() %>% kable_styling(bootstrap_options=c('striped'))
# Import conflict settings.
source('../src/conflicted.R')
# Load some libraries.
library(tidyverse)
library(ggplot2)
library(raster)
library(sf)
library(landscapemetrics)
library(knitr)
library(kableExtra)
library(broom)
library(AICcmodavg)
library(modelr)
# Load in the processed data from last time.
data <- read_csv('../data/processed/landscape_metrics_index.csv')
# Remove problematic TCR.
df <- data %>% filter(site != 'TCR')
View(df)
# Import conflict settings.
source('../src/conflicted.R')
#Load some libraries.
library(tidyverse)
library(vegan)
library(raster)
library(sf)
library(landscapemetrics)
library(broom)
library(knitr)
library(kableExtra)
library(GGally)
library(extrafont)
library(QuantPsyc)
# Area is in hectares.
landscape <- data.frame(
size=c('PFA', 'breeding area', 'home range', 'maximum range'),
area=c(60, 200, 3800, 15600)
)
# Convert area in hectares to radii in meters.
landscape <- landscape %>% mutate(radius=sqrt(area*10000/pi))
landscape
# Read in the data.
occupancy <- read_csv('../data/processed/occupancy_sc.csv')
# Calculate number of years NOGO detected out of number of years surveyed.
territory.quality <- occupancy %>% pivot_longer(-c(site, name), names_to='year', values_to='status') %>%
filter(status > 0) %>%
group_by(site, status) %>%
add_tally() %>%
distinct(site, status, .keep_all=TRUE) %>%
select(-year) %>%
pivot_wider(names_from=status, values_from=n, values_fill=0) %>%
ungroup() %>% rowwise(site, name) %>%
mutate(years.surveyed=sum(c(`3`, `2`, `1`)),
years.detect=sum(c(`3`, `2`)),
years.no.detect=years.surveyed-years.detect,
quality.index=years.detect/years.surveyed) %>%
select(site, name, years.surveyed, years.detect, years.no.detect, quality.index) %>%
filter(years.detect >= 1)
# Look at it.
territory.quality
# How many sites have occupancy data?
nrow(territory.quality)
# How many years have sites been surveyed?
mean(territory.quality$years.surveyed)
range(territory.quality$years.surveyed)
# What kind of quality do we see?
mean(territory.quality$quality.index)
sd(territory.quality$quality.index)
# Read in the data.
nests <- read_csv('../data/processed/sc_nests.csv')
# Calculate a centroid for each site.
centroids <- nests %>% group_by(site) %>%
mutate(xcoord=mean(xcoord), ycoord=mean(ycoord)) %>%
distinct(site, name, xcoord, ycoord) %>% ungroup()
# Make it a spatial object for later.
sites.sf <- centroids %>%
st_as_sf(coords=c('xcoord', 'ycoord')) %>%
st_set_crs('+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs')
# Also make a list of site names for later.
site.names <- sites.sf$site
# Load in the processed data from last time.
data <- read_csv('../data/processed/landscape_metrics_full.csv')
# Remove problematic TCR.
df <- data %>% filter(site != 'TCR')
View(df)
# Load all the rasters.
source('../src/load_rasters.R')
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE)
# Import conflict settings.
source('../src/conflicted.R')
#Load some libraries.
library(tidyverse)
library(vegan)
library(raster)
library(sf)
library(landscapemetrics)
library(broom)
library(knitr)
library(kableExtra)
library(GGally)
library(extrafont)
library(QuantPsyc)
# Area is in hectares.
landscape <- data.frame(
size=c('PFA', 'breeding area', 'home range', 'maximum range'),
area=c(60, 200, 3800, 15600)
)
# Convert area in hectares to radii in meters.
landscape <- landscape %>% mutate(radius=sqrt(area*10000/pi))
landscape
# Read in the data.
occupancy <- read_csv('../data/processed/occupancy_sc.csv')
# Calculate number of years NOGO detected out of number of years surveyed.
territory.quality <- occupancy %>% pivot_longer(-c(site, name), names_to='year', values_to='status') %>%
filter(status > 0) %>%
group_by(site, status) %>%
add_tally() %>%
distinct(site, status, .keep_all=TRUE) %>%
select(-year) %>%
pivot_wider(names_from=status, values_from=n, values_fill=0) %>%
ungroup() %>% rowwise(site, name) %>%
mutate(years.surveyed=sum(c(`3`, `2`, `1`)),
years.detect=sum(c(`3`, `2`)),
years.no.detect=years.surveyed-years.detect,
quality.index=years.detect/years.surveyed) %>%
select(site, name, years.surveyed, years.detect, years.no.detect, quality.index) %>%
filter(years.detect >= 1)
# Look at it.
territory.quality
# How many sites have occupancy data?
nrow(territory.quality)
# How many years have sites been surveyed?
mean(territory.quality$years.surveyed)
range(territory.quality$years.surveyed)
# What kind of quality do we see?
mean(territory.quality$quality.index)
sd(territory.quality$quality.index)
# Read in the data.
nests <- read_csv('../data/processed/sc_nests.csv')
# Calculate a centroid for each site.
centroids <- nests %>% group_by(site) %>%
mutate(xcoord=mean(xcoord), ycoord=mean(ycoord)) %>%
distinct(site, name, xcoord, ycoord) %>% ungroup()
# Make it a spatial object for later.
sites.sf <- centroids %>%
st_as_sf(coords=c('xcoord', 'ycoord')) %>%
st_set_crs('+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs')
# Also make a list of site names for later.
site.names <- sites.sf$site
# Load all the rasters.
source('../src/load_rasters.R')
# Calculate metrics for each site.
source('../src/calc_land_metrics.R')
# Load in a list of site names.
site.names <- read_csv('../data/processed/site_abbreviations.csv')
# Join the data together.
data <- full_join(site.names, bec.landscape.metrics, by=c('site'='nest')) %>%
full_join(suitable.landscape.metrics, by=c('site' = 'nest', 'radius', 'size')) %>%
full_join(landcover.landscape.metrics, by=c('site' = 'nest', 'radius', 'size')) %>%
full_join(hsi.landscape.metrics, by=c('site' = 'nest', 'radius', 'size')) %>%
full_join(gap.landscape.metrics, by=c('site' = 'nest', 'radius', 'size')) %>%
full_join(canopy.landscape.metrics, by=c('site' = 'nest', 'radius', 'size')) %>%
full_join(territory.quality, by=c('site', 'name'))
write_csv(data, '../data/processed/landscape_metrics_full.csv')
# Load in the processed data from last time.
data <- read_csv('../data/processed/landscape_metrics_full.csv')
View(data)
df %>% filter(is.na(years.surveyed))
df %>% filter(years.surveyed = is.na())
df %>% drop_na(years.surveyed)
df %>% drop_na()
drop_na(df)
4+5
drop_na(df)
drop_na(data)
# Remove problematic TCR.
df <- data %>% filter(site != 'TCR')
df %>% drop_na(years.surveyed)
df %>% filter_at(vars(contains('percent')), all_vars(. >=90))
# Load in the processed data from last time.
data <- read_csv('../data/processed/landscape_metrics_index.csv')
View(data)
# Load in the processed data from last time.
data <- read_csv('../data/processed/landscape_metrics_full.csv')
View(data)
df %>% filter_at(vars(contains('inside')), all_vars(. >=90))
# Load in the processed data from last time.
data <- read_csv('../data/processed/landscape_metrics_full.csv')
# Remove problematic TCR.
df <- data %>% filter(site != 'TCR')
# Keep only sites with occupancy data.
df <- df %>% drop_na(years.surveyed) #90
# Remove sites that are missing sufficient landscape data.
df <- df %>% filter_at(vars(contains('inside')), all_vars(. >=90))
# Load HSI raster.
r.hsi <- raster('../data/processed/foraging_sc.tif')
# Define levels.
hsi.levels <- data.frame(ID=c(-10, -2, -1, 0, 1, 2, 3),
class.name=c('ocean', 'freshwater', 'river',
'nil', 'low', 'moderate', 'high'))
# Add levels to raster.
levels(r.hsi) <- hsi.levels
# Assign crs to raster.
crs(r.hsi) <- CRS('+proj=utm +zone=10 +datum=NAD83 +units=m +no_defs')
# Define landscape sizes.
landscape <- data.frame(
size=c('PFA', 'breeding area', 'home range', 'maximum range'),
area=c(60, 200, 3800, 15600)
)
# Convert area in hectares to radii in meters.
landscape <- landscape %>% mutate(radius=sqrt(area*10000/pi))
# Read in the data.
nests <- read_csv('../data/processed/sc_nests.csv')
# Calculate a centroid for each site, and keep only ones with a quality index.
centroids <- nests %>% group_by(site) %>%
mutate(mean.x=mean(xcoord), mean.y=mean(ycoord)) %>%
distinct(site, name, mean.x, mean.y)
sites <- semi_join(centroids, data, by=c('site', 'name')) %>%
rename(xcoord=mean.x, ycoord=mean.y)
# Make it a spatial object for later.
sites.sf <- sites %>%
st_as_sf(coords=c('xcoord', 'ycoord')) %>%
st_set_crs('+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs') %>%
st_as_sf()
# Also make a list of site names for later.
site.names <- sites.sf$site
# Make a list of metrics to calculate.
hsi.metrics <- c('lsm_l_sidi')
# Make a function to do the calculations and formatting.
calc.hsi.metrics <- function(x) {
sample_lsm(r.hsi, y=sites.sf, size=x, plot_id=site.names, shape='circle',
what=hsi.metrics) %>%
left_join(hsi.levels, by=c('class'='ID')) %>%
mutate(class.name=ifelse(is.na(class.name), metric, class.name)) %>%
select(-class, -metric, -level) %>%
pivot_wider(names_from=class.name, values_from=value) %>%
mutate(radius=x) %>%
rename(hsi.inside=percentage_inside)
}
# Run the function for each sample size.
hsi.landscape.metrics <- map_df(landscape$radius, calc.hsi.metrics)
# Do some cleanup
hsi.landscape.metrics <- hsi.landscape.metrics %>%
select(radius, hsi.inside, nest=plot_id, hsi.diversity=sidi)
hsi.landscape.metrics <- select(landscape, radius, size) %>% right_join(hsi.landscape.metrics, by=c('radius'))
# Join to data frame.
df <- left_join(df, hsi.landscape.metrics, by=c('site'='nest', 'size', 'radius', 'hsi.inside'))
# Filter out any sites without sufficient landscape coverage.
df <- df %>% filter_at(vars(contains('inside')), all_vars(. >=90))
# Proportion suitable
proportion.suitable.model <- function(df) {
glm(cbind(years.detect, years.no.detect) ~ proportion.suitable, data=df, family=binomial(logit))
}
# Proportion suitable + HSI diversity
suitable.diversity.model <- function(df) {
glm(cbind(years.detect, years.no.detect) ~ proportion.suitable + hsi.diversity, data=df, family=binomial(logit))
}
# Proportion suitable + suitable edge density
suitable.edge.density.model <- function(df) {
glm(cbind(years.detect, years.no.detect) ~ proportion.suitable + suitable.edge.density, data=df, family=binomial(logit))
}
# Proportion suitable + HSI diversity + suitable edge density
suitable.sink.model <- function(df) {
glm(cbind(years.detect, years.no.detect) ~ proportion.suitable +
suitable.edge.density + hsi.diversity, data=df, family=binomial(logit))
}
# Proportion mature forest
proportion.mature.model <- function(df) {
glm(cbind(years.detect, years.no.detect) ~ proportion.cover.mature, data=df, family=binomial(logit))
}
# Proportion mature + landcover diversity
mature.diversity.model <- function(df) {
glm(cbind(years.detect, years.no.detect) ~ proportion.cover.mature + cover.diversity, data=df, family=binomial(logit))
}
# Proportion mature + gap edge density
mature.edge.density.model <- function(df) {
glm(cbind(years.detect, years.no.detect) ~ proportion.cover.mature + gap.edge.density, data=df, family=binomial(logit))
}
# Proportion mature + gap edge density + landcover diversity
mature.sink.model <- function(df) {
glm(cbind(years.detect, years.no.detect) ~ proportion.cover.mature +
gap.edge.density + cover.diversity, data=df, family=binomial(logit))
}
# Null
null.model <- function(df) {
glm(cbind(years.detect, years.no.detect) ~ 1, data=df, family=binomial(logit))
}
# Nest the data frame.
nf <- df %>% group_by(size) %>% nest()
# Apply the functions.
nf <- nf %>%
mutate(
m.proportion.suitable=map(data, proportion.suitable.model),
m.suitable.diversity=map(data, suitable.diversity.model),
m.suitable.edge.density=map(data, suitable.edge.density.model),
m.suitable.sink=map(data, suitable.sink.model),
m.proportion.mature=map(data, proportion.mature.model),
m.mature.diversity=map(data, mature.diversity.model),
m.mature.edge.density=map(data, mature.edge.density.model),
m.mature.sink=map(data, mature.sink.model),
m.null=map(data, null.model)
)
all.models <- nf %>% pivot_longer(-c(size, data), names_to='modname', values_to='model') %>%
mutate(name=paste(size, modname))
aictab(all.models$model, modnames=all.models$name) %>%
kable() %>% kable_styling(bootstrap_options=c('striped'))
pfa.models <- nf %>% filter(size == 'PFA') %>%
pivot_longer(-c(size, data), names_to='modname', values_to='model')
ba.models <- nf %>% filter(size == 'breeding area') %>%
pivot_longer(-c(size, data), names_to='modname', values_to='model')
hr.models <- nf %>% filter(size == 'home range') %>%
pivot_longer(-c(size, data), names_to='modname', values_to='model')
mr.models <- nf %>% filter(size == 'maximum range') %>%
pivot_longer(-c(size, data), names_to='modname', values_to='model')
aictab(pfa.models$model, modnames=pfa.models$modname) %>%
kable() %>% kable_styling(bootstrap_options=c('striped'))
# Separate out the data.
pfa.data <- df %>% filter(size == 'PFA')
# Re-write the top model on its own.
pfa.top.model <- glm(cbind(years.detect, years.no.detect) ~ proportion.cover.mature +
gap.edge.density, data=pfa.data, family=binomial(logit))
# Create a grid and add predictions.
pfa.predicted <- data_grid(pfa.data, gap.edge.density, .model=pfa.top.model) %>%
mutate(pred=predict(pfa.top.model, newdata=., type='response'))
# Grab the inverse link function from the model.
inv <- family(pfa.top.model)$linkinv
# Add fit and SE data.
pfa.predicted <- bind_cols(pfa.predicted, setNames(as_tibble(predict(pfa.top.model, pfa.predicted,
se.fit = TRUE)[1:2]),
c('fit.link','se.link')))
# Create confidence interval.
pfa.predicted <- pfa.predicted %>% mutate(fit.resp  = inv(fit.link),
right.upr = inv(fit.link + (2 * se.link)),
right.lwr = inv(fit.link - (2 * se.link)))
# Plot them?
ggplot(pfa.predicted, aes(x=gap.edge.density, y=pred)) +
geom_line() +
geom_ribbon(aes(ymin=right.lwr, ymax=right.upr), alpha=0.1) +
geom_point(data=pfa.data, aes(x=gap.edge.density, y=quality.index)) +
theme_classic()
summary(pfa.top.model)
# Look at some diagnostics.
data.frame(predicted=predict(pfa.top.model, type='response'),
residuals=residuals(pfa.top.model, type='response')) %>%
ggplot(aes(x=predicted, y=residuals)) +
geom_point() +
geom_hline(yintercept=0, linetype='dashed') +
geom_smooth(method='lm', se=FALSE, color='black') +
theme_classic()
pfa.models %>% mutate(glance=map(model, glance)) %>%
unnest(glance) %>% ungroup() %>%
select(!c(size, data, model))
pfa.models %>% mutate(tidy=map(model, tidy)) %>%
unnest(tidy) %>% ungroup() %>%
select(!c(size, data, model)) %>%
filter(term != '(Intercept)')
aictab(ba.models$model, modnames=ba.models$modname) %>%
kable() %>% kable_styling(bootstrap_options=c('striped'))
# Separate out the data.
ba.data <- df %>% filter(size == 'breeding area')
# Re-write the top model on its own.
ba.top.model <- glm(cbind(years.detect, years.no.detect) ~ proportion.cover.mature +
gap.edge.density, data=ba.data, family=binomial(logit))
# Create a grid and add predictions.
ba.predicted <- data_grid(ba.data, gap.edge.density, .model=ba.top.model) %>%
mutate(pred=predict(ba.top.model, newdata=., type='response'))
# Grab the inverse link function from the model.
ba.inv <- family(ba.top.model)$linkinv
# Add fit and SE data.
ba.predicted <- bind_cols(ba.predicted, setNames(as_tibble(predict(ba.top.model, ba.predicted,
se.fit = TRUE)[1:2]),
c('fit.link','se.link')))
# Create confidence interval.
ba.predicted <- ba.predicted %>% mutate(fit.resp  = ba.inv(fit.link),
right.upr = ba.inv(fit.link + (2 * se.link)),
right.lwr = ba.inv(fit.link - (2 * se.link)))
# Plot them?
ggplot(ba.predicted, aes(x=gap.edge.density, y=pred)) +
geom_line() +
geom_ribbon(aes(ymin=right.lwr, ymax=right.upr), alpha=0.1) +
geom_point(data=ba.data, aes(x=gap.edge.density, y=quality.index)) +
theme_classic()
summary(ba.top.model)
# Look at some diagnostics.
data.frame(predicted=predict(ba.top.model, type='response'),
residuals=residuals(ba.top.model, type='response')) %>%
ggplot(aes(x=predicted, y=residuals)) +
geom_point() +
geom_hline(yintercept=0, linetype='dashed') +
geom_smooth(method='lm', se=FALSE, color='black') +
theme_classic()
ba.models %>% mutate(glance=map(model, glance)) %>%
unnest(glance) %>% ungroup() %>%
select(!c(size, data, model))
ba.models %>% mutate(tidy=map(model, tidy)) %>%
unnest(tidy) %>% ungroup() %>%
select(!c(size, data, model)) %>%
filter(term != '(Intercept)')
aictab(hr.models$model, modnames=hr.models$modname) %>%
kable() %>% kable_styling(bootstrap_options=c('striped'))
hr.models %>% mutate(glance=map(model, glance)) %>%
unnest(glance) %>% ungroup() %>%
select(!c(size, data, model))
hr.models %>% mutate(tidy=map(model, tidy)) %>%
unnest(tidy) %>% ungroup() %>%
select(!c(size, data, model)) %>%
filter(term != '(Intercept)')
aictab(mr.models$model, modnames=mr.models$modname) %>%
kable() %>% kable_styling(bootstrap_options=c('striped'))
mr.models %>% mutate(glance=map(model, glance)) %>%
unnest(glance) %>% ungroup() %>%
select(!c(size, data, model))
mr.models %>% mutate(tidy=map(model, tidy)) %>%
unnest(tidy) %>% ungroup() %>%
select(!c(size, data, model)) %>%
filter(term != '(Intercept)')
