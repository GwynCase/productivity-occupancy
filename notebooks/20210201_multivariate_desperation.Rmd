---
title: "Multivariate desperation"
output: html_notebook
always_allow_html: true
---

```{r options, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE)
```

Playing with multivariate models that probs won't work but oh well.

```{r message=FALSE, warning=FALSE}
# Import conflict settings.
source('../src/conflicted.R')

# Load some libraries.
library(tidyverse)
library(ggplot2)
library(raster)
library(sf)
library(landscapemetrics)
library(knitr)
library(kableExtra)
library(GGally)
library(broom)
library(QuantPsyc)

# Load in the processed data from last time.
data <- read_csv('../data/processed/landscape_metrics_index.csv')

# Remove problematic TCR.
df <- data %>% filter(site != 'TCR')
```

What are some candidate models?

* Proportion suitable
* Proportion suitable + suitable edge density
* Proportion mature
* Proportion mature + landcover diversity
* Proportion mature + gap edge density

The problem is that with four spatial scales, these escalate quickly. Each bivariate models has... what? `r 4*4` possible combinations?  With three bivariate models and two univariates that's `r 4*4*3 + 4 + 4` models. Which is insane.

Let's stick to one-size-at-a-time for now.

# The models

```{r}
# Proportion suitable
proportion.suitable.model <- function(df) {
  glm(cbind(years.detect, years.no.detect) ~ proportion.suitable, data=df, family=binomial(logit))
}

# Proportion suitable + suitable edge density
suitable.edge.density.model <- function(df) {
  glm(cbind(years.detect, years.no.detect) ~ proportion.suitable + suitable.edge.density, data=df, family=binomial(logit))
}

# Proportion mature forest
proportion.mature.model <- function(df) {
  glm(cbind(years.detect, years.no.detect) ~ proportion.cover.mature, data=df, family=binomial(logit))
}

# Proportion mature + landcover diversity
mature.diversity.model <- function(df) {
  glm(cbind(years.detect, years.no.detect) ~ proportion.cover.mature + cover.diversity, data=df, family=binomial(logit))
}

# Proportion mature + gap edge density
mature.edge.density.model <- function(df) {
  glm(cbind(years.detect, years.no.detect) ~ proportion.cover.mature + gap.edge.density, data=df, family=binomial(logit))
}

# Null
null.model <- function(df) {
  glm(cbind(years.detect, years.no.detect) ~ 1, data=df, family=binomial(logit))
}
```

Then nest the data frame for ease of coding and apply each function to generate a disturbingly large number of models really fast.

```{r warning=FALSE}
# Nest the data frame.
nf <- df %>% group_by(size) %>% nest()

# Apply the functions.
nf <- nf %>% 
  mutate(
    m.proportion.suitable=map(data, proportion.suitable.model),
    m.suitable.edge.density=map(data, suitable.edge.density.model),
    m.proportion.mature=map(data, proportion.mature.model),
    m.mature.diversity=map(data, mature.diversity.model),
    m.mature.edge.density=map(data, mature.edge.density.model),
    m.null=map(data, null.model)
         )
```

Now let's assess.

```{r warning=FALSE}
nf.long <- nf %>% 
  pivot_longer(-c(size, data), names_to='modname', values_to='model') %>% 
  mutate(glance=map(model, glance))

# Take a look.
nf.long %>%
  unnest(glance) %>% 
  select(-model, -data) %>% 
  arrange(AIC) %>% 
  kable() %>% kable_styling(bootstrap_options=c('striped'))
```


